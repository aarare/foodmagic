{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-Vy7efLCwA7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "import pymongo\n",
        "import certifi\n",
        "import re\n",
        "import string\n",
        "\n",
        "from os import path, getcwd\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX6D9sHuCwBA"
      },
      "outputs": [],
      "source": [
        "def read_from_food_metadata(collection): # collection is string\n",
        "    \n",
        "    global df_dicts\n",
        "    \n",
        "    client = pymongo.MongoClient('your mongodb uri', ssl_ca_certs=certifi.where())\n",
        "    db = client.food_metadata\n",
        "    \n",
        "    data = db.get_collection(collection)\n",
        "    \n",
        "    item_details1 = data.find()\n",
        "    dicts1 = []\n",
        "    for item in item_details1:\n",
        "        dicts1.append(item)\n",
        "    \n",
        "    df_dicts = pd.DataFrame.from_dict(dicts1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MW5nidlCwBA"
      },
      "outputs": [],
      "source": [
        "def preprocessing(collection):\n",
        "    \n",
        "    global df_dicts, df_new, df\n",
        "     \n",
        "    df = df_dicts.copy()\n",
        "    df['food_id'] = df.groupby(['food_name']).ngroup()\n",
        "    \n",
        "    def replace_columns(column, context):\n",
        "        df[column] = [str(i).replace(context, \"\") for i in df[column]]\n",
        "    \n",
        "    def new_column(column):\n",
        "        df[column] = [float(str(i).replace(\",\", \"\")) for i in df[column]]\n",
        "    \n",
        "    #rating\n",
        "    replace_columns(\"rating\", \"Ratings\")\n",
        "    replace_columns(\"rating\", \"Rating\")\n",
        "    new_column(\"rating\")\n",
        "    \n",
        "    #review_count\n",
        "    replace_columns(\"review_count\", \"Reviews\")\n",
        "    replace_columns(\"review_count\", \"Review\")\n",
        "    new_column(\"review_count\")\n",
        "    \n",
        "    #photo_count\n",
        "    replace_columns(\"photo_count\", \"Photos\")\n",
        "    replace_columns(\"photo_count\", \"Photo\")\n",
        "    new_column(\"photo_count\")\n",
        "    \n",
        "    #total_time\n",
        "    df[['sayi1', 'mins_hr', 'sayi2', 'mins']] = df['total_time'].str.split(' ', expand=True, n=3).fillna(0)\n",
        "    df['sayi1'] = df['sayi1'].astype(int)\n",
        "    df['sayi2'] = df['sayi2'].astype(int)\n",
        "    df['sayi1'] = np.where(df['mins_hr'] == 'hr', df['sayi1'] * 60 + df['sayi2'], df['sayi1'])\n",
        "    df.drop(['mins_hr', 'sayi2', 'mins'], axis=1, inplace=True)\n",
        "    df = df.rename(columns={'sayi1': 'total_time_new'})\n",
        "    df[\"total_time_new\"].replace(0, np.nan, inplace=True)\n",
        "    \n",
        "    #for lowcholesterol collection\n",
        "    if (i == 'lowcholesterol'):\n",
        "        chainlist = df.iloc[0:353, :]\n",
        "        chainstr = df.iloc[353:943, :]\n",
        "        chainstr[\"chain\"] = chainstr[\"chain\"].apply(eval)\n",
        "        df = pd.concat([chainlist, chainstr], axis=0)\n",
        "    \n",
        "    #for regex funcs\n",
        "    alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
        "    punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "    \n",
        "    \n",
        "    #ingredients\n",
        "    if (i == 'gluten_free') | (i ==  'keto') | (i == 'vegan'):\n",
        "        df['ingredients_new'] = df['ingredients'].apply(eval)\n",
        "        df[\"ingredients_new\"] = [','.join(map(str, l)) for l in df['ingredients_new']]\n",
        "    else:\n",
        "        df[\"ingredients_new\"] = [','.join(map(str, l)) for l in df['ingredients']] #liste olduğundan strye çevirdim ki map uygulansın\n",
        "    \n",
        "    df['ingredients_new'] = df['ingredients_new'].map(alphanumeric).map(punc_lower).str.strip()\n",
        "    words = [\"teaspoon\",\"teaspoons\", \"tablespoon\",\"tablespoons\", \"fluid ounce\",\"gill\",\"cup\",\"cups\", \"pint\",\"quart\",\n",
        "             \"gallon\",\"ml\",\"liter\", \"pound\",\"ounce\",\"ounces\", \"mg\",\"gram\",\"kg\",\"length\",\"mm\",\"cm\",\"meter\",\"inch\", \n",
        "             \"chopped\", \"taste\", \"water\", \"ground\", \"large\", \"sliced\", \"diced\", 'cut', 'into', 'black', 'pepper', \n",
        "             \"salt\", 'white', 'sugar', 'olive', 'oil', 'clove', 'garlic', 'onion', 'minced', 'tomato', 'optional', \n",
        "             'fresh', 'crushed', 'drained', 'rinsed', 'purpose', 'flour', 'lemon', 'juice', 'clove', 'cooking', 'sprey',\n",
        "             'finely', 'dried', 'small', 'baking', 'powder', 'vanilla', 'extract', 'heavy', 'whipping', 'pinch', 'thinly',\n",
        "             'peeled', 'extra', 'virgin', \"½\", \"¼\", \"⅓\", \"¾\", \"⅛\", \"⅔\"]\n",
        "    df['ingredients_new'] = df['ingredients_new'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "    #for WordCloud\n",
        "    text=\" \".join(i for i in df['ingredients_new'])\n",
        "    wordcloud=WordCloud(width=600, height=250, max_font_size=50, max_words=2000, background_color=\"white\").generate(text)\n",
        "    plt.figure(figsize=[50,50])\n",
        "    #plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    #plt.axis(\"off\")\n",
        "    wordcloud.to_file(collection + '.png');\n",
        "    #for stopwords in ingredients\n",
        "    import nltk\n",
        "    #nltk.download('stopwords')\n",
        "    from nltk.corpus import stopwords\n",
        "    sw = stopwords.words('english')\n",
        "    df['ingredients_new'] = df['ingredients_new'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
        "    #for lemmi in ingredients\n",
        "    from textblob import Word\n",
        "    #nltk.download('wordnet')\n",
        "    df['ingredients_new'] = df['ingredients_new'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "    \n",
        "    #nutrition\n",
        "    replace_columns(\"nutrition\", \". Full Nutrition\")\n",
        "    nutrition_list = [\"protein\", \"carbohydrates\", \"fat\", \"cholesterol\", \"sodium\"]\n",
        "    df['nutrition_new'] = df['nutrition'].apply(lambda x: \" \".join(x for x in x.split() if x not in nutrition_list))\n",
        "    replace_columns(\"nutrition_new\", \" calories\")\n",
        "    replace_columns(\"nutrition_new\", \"g\")\n",
        "    replace_columns(\"nutrition_new\", \"m\")\n",
        "    df[[\"calories\", \"protein_gr\", \"carbohydrates_gr\", \"fat_gr\", \"cholesterol_mg_sodium_mg\"]] = df['nutrition_new'].str.split(';', expand=True, n=4)\n",
        "    df['calories'] = df['calories'].str.strip()\n",
        "    df['protein_gr'] = df['protein_gr'].str.strip()\n",
        "    df['carbohydrates_gr'] = df['carbohydrates_gr'].str.strip()\n",
        "    df['fat_gr'] = df['fat_gr'].str.strip()\n",
        "    df[['cho', 'so']] = df[\"cholesterol_mg_sodium_mg\"].str.split(';', expand=True)\n",
        "    df['cho'] = df['cho'].str.strip()\n",
        "    df['so'] = df['so'].str.strip()\n",
        "    df[['cho', 'so']] = df[['cho', 'so']].fillna(0)\n",
        "    df['so'] = np.where(df['so'] == 0, df['cho'], df['so']) #Analiz icin unknown degil de 0 yaptim\n",
        "    df['cho'] = np.where(df['cho'] == df['so'], 0, df['cho']) #Analiz icin unknown degil de 0 yaptim\n",
        "    df.drop([\"nutrition_new\", 'cholesterol_mg_sodium_mg'], axis=1, inplace=True)\n",
        "    df = df.rename(columns = {'cho': 'cholesterol_mg', 'so': 'sodium_mg'})\n",
        "    df[['rating', 'review_count', 'photo_count', 'total_time_new', 'calories', 'protein_gr', 'carbohydrates_gr', \n",
        "        'fat_gr', 'cholesterol_mg', 'sodium_mg']] = df[['rating', 'review_count', 'photo_count', 'total_time_new', \n",
        "                                                        'calories', 'protein_gr', 'carbohydrates_gr', 'fat_gr', \n",
        "                                                        'cholesterol_mg', 'sodium_mg']].astype(float)\n",
        "    \n",
        "    df_new = df.copy()\n",
        "    \n",
        "    #chain\n",
        "    if (collection == 'gluten_free') | (collection ==  'keto') | (collection == 'vegan'):\n",
        "        df_new[\"chain\"] = df_new[\"chain\"].apply(eval)\n",
        "        print('bu collection', collection)\n",
        "    else:\n",
        "        print('gluten,keto,vegan degil')\n",
        "        \n",
        "    df_new = df_new.explode('chain').reset_index(drop=True)\n",
        "    \n",
        "    if (collection == 'vegan') | (collection ==  'vegetarian'):\n",
        "        df_new[[\"users\", \"stars\", 'Nonecolumn']] = df_new['chain'].str.split(pat=\"Rating: \", expand=True)\n",
        "    else:    \n",
        "        df_new[[\"users\", \"stars\"]] = df_new['chain'].str.split(pat=\"Rating: \", expand=True)\n",
        "        \n",
        "    df_new[['stars', \"reviews\"]] = df_new['stars'].str.split(pat=\" stars       \", expand=True)\n",
        "    df_new[[\"redundant1\", \"redudant2\", 'reviews']] = df_new['reviews'].str.split(pat=\"/\", n=2, expand=True)\n",
        "    df_new.drop([\"chain\", \"redundant1\", \"redudant2\"], axis=1, inplace=True)\n",
        "    df_new[\"stars\"] = df_new[\"stars\"].astype(float)\n",
        "    df_new[\"users\"] = df_new[\"users\"].str.strip()\n",
        "    \n",
        "    #reviews\n",
        "    df_new[\"reviews\"] = df_new[\"reviews\"].str.replace(\" Read More     \", \"\")\n",
        "    df_new[\"reviews\"] = df_new[\"reviews\"].str.replace('(\\d+)', '').str.strip()\n",
        "    df_new = df_new.drop_duplicates(subset=\"reviews\")\n",
        "    df_new.drop(['_id', 'index'], axis=1, inplace=True)\n",
        "    \n",
        "    #for filling NaNs\n",
        "    df_new['total_time_new'].fillna(df_new['total_time_new'].median(), inplace=True)\n",
        "    fill_columns= ['photo_count', 'calories', 'carbohydrates_gr', 'fat_gr', 'cholesterol_mg', 'sodium_mg']\n",
        "    for column in fill_columns:\n",
        "        df_new[column] = df_new[column].fillna(0)\n",
        "    \n",
        "    #for recommendation\n",
        "    df_new['userid'] = df_new.groupby(['users']).ngroup()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf2VAaVzCwBC"
      },
      "outputs": [],
      "source": [
        "def load_to_food_recommendation(collection_name): # collection_name is string\n",
        "    \n",
        "    global df_new\n",
        "    \n",
        "    client = pymongo.MongoClient('your mongodb uri', ssl_ca_certs=certifi.where())\n",
        "    db = client.food_recommendation\n",
        "    collection = db[collection_name]\n",
        "\n",
        "    df_new.reset_index(inplace=True)\n",
        "    data_dict = df_new.to_dict(\"records\")\n",
        "\n",
        "    collection.insert_many(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WvAQw0KCwBD"
      },
      "outputs": [],
      "source": [
        "collection = ['diabetic', 'gluten_free', 'keto', 'lowsodium', 'low_cholesterol', 'vegan', 'vegetarian']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h86Xo8Z3CwBD",
        "outputId": "4d100ba3-4e59-4f79-dc7e-b914871adc3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bu collection vegan\n",
            "vegan\n",
            "gluten,keto,vegan degil\n",
            "vegetarian\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 3600x3600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 3600x3600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in collection:\n",
        "    read_from_food_metadata(i)\n",
        "    preprocessing(i)\n",
        "    load_to_food_recommendation(i)\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy4o18XfCwBE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFi9eWySCwBF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "alldata_process github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}